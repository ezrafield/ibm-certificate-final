{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os \nimport torch\nimport numpy as np\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets.folder import default_loader\nfrom torchvision import transforms\nimport torchvision.models as models","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:44:17.297511Z","iopub.execute_input":"2022-03-07T08:44:17.298018Z","iopub.status.idle":"2022-03-07T08:44:18.915818Z","shell.execute_reply.started":"2022-03-07T08:44:17.29781Z","shell.execute_reply":"2022-03-07T08:44:18.915101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# idea: https://www.kaggle.com/khoatran1312/dog-cat-classification","metadata":{}},{"cell_type":"code","source":"# hyperparams\n\nCLASSES = {0:\"cat\", 1:\"dog\"}\nBATCH_SIZE = 64\nIMG_SIZE = (224, 224)\nNUM_EPOCHS = 50\nTRAIN_DATA_PATH = \"../input/dog-vs-cat/train/train\"\nTEST_DATA_PATH = \"../input/dog-vs-cat/test/test\"\nTRANSFORM_IMG = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize(IMG_SIZE),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225] )\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:44:18.917447Z","iopub.execute_input":"2022-03-07T08:44:18.917675Z","iopub.status.idle":"2022-03-07T08:44:18.923829Z","shell.execute_reply.started":"2022-03-07T08:44:18.917642Z","shell.execute_reply":"2022-03-07T08:44:18.922877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# custom dataloader for testing samples\nclass TestingDataset(Dataset):\n    \n    def __init__(self, root, transforms=None):\n        self.transforms = transforms\n        self.img_paths = sorted(os.path.join(root, x) for x in os.listdir(root) if x.endswith('.jpg'))\n\n        \n    def __len__(self):\n        return len(self.img_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.img_paths[idx]\n        sample = default_loader(img_path)\n        if self.transforms is not None:\n            sample = self.transforms(sample)\n        return sample, img_path.split('/')[-1]","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:44:18.925228Z","iopub.execute_input":"2022-03-07T08:44:18.925777Z","iopub.status.idle":"2022-03-07T08:44:18.934112Z","shell.execute_reply.started":"2022-03-07T08:44:18.925718Z","shell.execute_reply":"2022-03-07T08:44:18.933289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data loader\ntrain_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\ntrain_data_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\ntest_data = TestingDataset(root=TEST_DATA_PATH, transforms=TRANSFORM_IMG)\ntest_data_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:44:18.9364Z","iopub.execute_input":"2022-03-07T08:44:18.936718Z","iopub.status.idle":"2022-03-07T08:44:52.993928Z","shell.execute_reply.started":"2022-03-07T08:44:18.936685Z","shell.execute_reply":"2022-03-07T08:44:52.993223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.vgg16_bn(pretrained=False, num_classes=2)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:44:52.995281Z","iopub.execute_input":"2022-03-07T08:44:52.995763Z","iopub.status.idle":"2022-03-07T08:44:58.145447Z","shell.execute_reply.started":"2022-03-07T08:44:52.995726Z","shell.execute_reply":"2022-03-07T08:44:58.14469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:44:58.146858Z","iopub.execute_input":"2022-03-07T08:44:58.147118Z","iopub.status.idle":"2022-03-07T08:44:58.15202Z","shell.execute_reply.started":"2022-03-07T08:44:58.147084Z","shell.execute_reply":"2022-03-07T08:44:58.151383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training\nmodel.train()\n\nfor epoch in range(NUM_EPOCHS): \n    running_loss = 0.0\n    \n    for i, (img,label) in enumerate(train_data_loader):\n\n        inputs, labels = img.to(device), label.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()                                                                                                                                                                                                                                                                                                                                                                                                              \n\n    print('[%d, %5d] loss: %.3f' % (epoch + 1, epoch, running_loss / len(train_data_loader)))\n    running_loss = 0.0\nprint('[INFO]: Finished Training')  \n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:44:58.15316Z","iopub.execute_input":"2022-03-07T08:44:58.153804Z","iopub.status.idle":"2022-03-07T13:27:31.458256Z","shell.execute_reply.started":"2022-03-07T08:44:58.153767Z","shell.execute_reply":"2022-03-07T13:27:31.457539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PATH = f'./vgg16-plain-{NUM_EPOCHS}.pth'\n# torch.save(model.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:27:31.459461Z","iopub.execute_input":"2022-03-07T13:27:31.459703Z","iopub.status.idle":"2022-03-07T13:27:31.464636Z","shell.execute_reply.started":"2022-03-07T13:27:31.45967Z","shell.execute_reply":"2022-03-07T13:27:31.463896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing\n\nprint('[INFO]: Start Testing')\nmodel.eval()\n\nresult_array, image_paths = np.array([]), np.array([])\n \nwith torch.no_grad():\n    for i, (image, image_path) in enumerate(test_data_loader):\n        test_input = image.to(device)\n        outputs = model(test_input)\n        _, predicted = torch.max(outputs, 1)\n        result_array = np.append(result_array, predicted.cpu().detach().numpy())\n        image_paths = np.append(image_paths, image_path)\n                \n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:27:31.466001Z","iopub.execute_input":"2022-03-07T13:27:31.466257Z","iopub.status.idle":"2022-03-07T13:29:35.607175Z","shell.execute_reply.started":"2022-03-07T13:27:31.46622Z","shell.execute_reply":"2022-03-07T13:29:35.606427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_array = result_array.astype('uint8')\nresult_array","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:29:35.609558Z","iopub.execute_input":"2022-03-07T13:29:35.609875Z","iopub.status.idle":"2022-03-07T13:29:35.616976Z","shell.execute_reply.started":"2022-03-07T13:29:35.609798Z","shell.execute_reply":"2022-03-07T13:29:35.616301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualization \n\nfor i in range(12):\n    plt.subplot(3, 4,i+1)\n    image = plt.imread(os.path.join(TEST_DATA_PATH, image_paths[i]))\n    plt.imshow(image)\n    plt.axis(\"off\")\n    title = CLASSES[int(result_array[i])]\n    plt.title(f\"label: {title}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:29:35.618299Z","iopub.execute_input":"2022-03-07T13:29:35.618821Z","iopub.status.idle":"2022-03-07T13:29:36.436253Z","shell.execute_reply.started":"2022-03-07T13:29:35.618739Z","shell.execute_reply":"2022-03-07T13:29:36.434692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission \n\nimport pandas as pd\n\ndf = pd.DataFrame({'id': image_paths, 'labels': result_array})\ndf.to_csv('submission1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:30:56.732292Z","iopub.execute_input":"2022-03-07T13:30:56.732551Z","iopub.status.idle":"2022-03-07T13:30:56.754792Z","shell.execute_reply.started":"2022-03-07T13:30:56.732523Z","shell.execute_reply":"2022-03-07T13:30:56.754169Z"},"trusted":true},"execution_count":null,"outputs":[]}]}